{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "import copy\n",
    "\n",
    "import logging\n",
    "from src.utils import logging_utils\n",
    "from src import functional\n",
    "from src.models import ModelandTokenizer\n",
    "from src.dataset import load_dataset, load_relation, fill_template\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=logging_utils.DEFAULT_FORMAT,\n",
    "    datefmt=logging_utils.DEFAULT_DATEFMT,\n",
    "    stream=sys.stdout,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb74234e74864d36998c38f6daf402d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-15 15:31:46 src.models INFO     loaded model <meta-llama/Llama-2-7b-hf> | size: 12980.516 MB\n"
     ]
    }
   ],
   "source": [
    "from src.models import ModelandTokenizer\n",
    "\n",
    "model_name = \"meta-llama/Llama-2-7b-hf\"\n",
    "mt = ModelandTokenizer(model_path=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! This filtering strategy may cause problem for `gender_head_of_govt`, the model is almost always happy to predict `male` with zero-shot\n",
    "\n",
    "# relation = load_relation(\n",
    "#     relation_file = \"head_of_government.json\",\n",
    "#     num_icl = 0,                          # initialize with zero-shot\n",
    "#     default_path=\"../data\",\n",
    "#     batch_size=500\n",
    "# )\n",
    "\n",
    "# all_samples = copy.deepcopy(relation.samples)\n",
    "\n",
    "# # filter zero-shot model knowledge\n",
    "# relation = functional.filter_samples_by_model_knowledge(\n",
    "#     mt = mt,\n",
    "#     relation = relation,\n",
    "# )\n",
    "\n",
    "# relation.properties[\"num_icl\"] = 5\n",
    "# relation.select_icl_examples(num_icl=5)\n",
    "\n",
    "# relation.samples = all_samples\n",
    "\n",
    "# # filter model knowledge with `num_icl` shots\n",
    "# relation = functional.filter_samples_by_model_knowledge(\n",
    "#     mt = mt,\n",
    "#     relation = relation,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-15 16:03:04 src.dataset INFO     initialized relation -> \"gender head of govt\" with 7757 samples\n",
      "2023-12-15 16:03:04 src.functional INFO     filtered 120 with var=2015, from gender head of govt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'man': 109, 'woman': 6}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.dataset import balance_samples\n",
    "\n",
    "relation = load_relation(\n",
    "    relation_file = \"gender_head_of_govt.json\",\n",
    "    num_icl = 5,                          # initialize with 5-shot\n",
    "    default_path=\"../data\",\n",
    "    # batch_size=500\n",
    ")\n",
    "\n",
    "relation = functional.filter_samples_by_var(relation = relation, var = \"2015\")\n",
    "\n",
    "relation.range_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-15 16:03:10 src.functional INFO     filtered relation \"gender head of govt\" to 103 samples (with 5-shots)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'woman': 4, 'man': 4}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relation = functional.filter_samples_by_model_knowledge(\n",
    "    mt = mt,\n",
    "    relation = relation,\n",
    ")\n",
    "\n",
    "relation.samples = balance_samples(relation.samples)\n",
    "\n",
    "relation.range_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In <var>, {}'s <role> was a\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from relations.src.operators import JacobianIclMeanEstimator\n",
    "import relations.src.functional as relations_functional\n",
    "\n",
    "# relations_functional.make_prompt = functional.make_prompt\n",
    "relation.prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"In 2015, North Korea's Supreme Leader was a man\",\n",
       " \"In 2015, South Korea's President was a woman\",\n",
       " \"In 2015, Central African Republic's President was a woman\",\n",
       " \"In 2015, Eritrea's President was a man\",\n",
       " \"In 2015, Madagascar's President was a man\"]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relation.few_shot_demonstrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = JacobianIclMeanEstimator(\n",
    "    mt = mt,\n",
    "    h_layer = 8,\n",
    "    beta = 5.0\n",
    ")\n",
    "\n",
    "lre = estimator(relation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 2015, North Korea's Supreme Leader was a man\n",
      "In 2015, South Korea's President was a woman\n",
      "In 2015, Central African Republic's President was a woman\n",
      "In 2015, Eritrea's President was a man\n",
      "In 2015, Madagascar's President was a man\n",
      "In <var>, {}'s <role> was a\n"
     ]
    }
   ],
   "source": [
    "print(lre.prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample.subject='Liberia' (2015), sample.object='woman', predicted=\"man\", (p=0.136), known=(✗)\n",
      "sample.subject='Chile' (2015), sample.object='woman', predicted=\"woman\", (p=0.173), known=(✓)\n",
      "sample.subject='Benin' (2015), sample.object='man', predicted=\"young\", (p=0.121), known=(✗)\n",
      "sample.subject='India' (2015), sample.object='man', predicted=\"man\", (p=0.197), known=(✓)\n",
      "sample.subject='Germany' (2015), sample.object='woman', predicted=\"man\", (p=0.272), known=(✗)\n",
      "sample.subject='Norway' (2015), sample.object='woman', predicted=\"woman\", (p=0.276), known=(✓)\n",
      "sample.subject='United Arab Emirates' (2015), sample.object='man', predicted=\"man\", (p=0.191), known=(✓)\n",
      "sample.subject=\"Côte d'Ivoire\" (2015), sample.object='man', predicted=\"man\", (p=0.152), known=(✓)\n",
      "------------------------------------------------------------\n",
      "Faithfulness (@1) = 0.625\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "wrong = 0\n",
    "for sample in relation.samples:\n",
    "    predictions = lre(sample = sample).predictions\n",
    "    known_flag = functional.is_nontrivial_prefix(\n",
    "        prediction=predictions[0].token, target=sample.object\n",
    "    )\n",
    "    print(f\"{sample.subject=} ({sample.placeholders['<var>']}), {sample.object=}, \", end=\"\")\n",
    "    print(f'predicted=\"{functional.format_whitespace(predictions[0].token)}\", (p={predictions[0].prob:.3f}), known=({functional.get_tick_marker(known_flag)})')\n",
    "    \n",
    "    correct += known_flag\n",
    "    wrong += not known_flag\n",
    "    \n",
    "faithfulness = correct/(correct + wrong)\n",
    "\n",
    "print(\"------------------------------------------------------------\")\n",
    "print(f\"Faithfulness (@1) = {faithfulness}\")\n",
    "print(\"------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[PredictedToken(token='female', token_id=12944, prob=0.5100888013839722),\n",
       "  PredictedToken(token='male', token_id=14263, prob=0.4867301285266876),\n",
       "  PredictedToken(token='woman', token_id=6114, prob=0.0015251379227265716),\n",
       "  PredictedToken(token='man', token_id=767, prob=0.0005108572077006102),\n",
       "  PredictedToken(token='Male', token_id=27208, prob=0.00014185991312842816)]]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = relation[0][0]\n",
    "\n",
    "functional.predict_next_token(\n",
    "    mt = mt,\n",
    "    prompt = prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
